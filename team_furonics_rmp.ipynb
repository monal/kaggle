{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate My Professor - Team Furonics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model used was **Ridge Regression**. Features included - comments, tags, grades, interest and textbookuse. \n",
    "\n",
    "Takeaways - FeatureUnion and Pipelines, clipping."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read in the train and test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\"train.csv\")\n",
    "test_data = pd.read_csv(\"test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 1: Comments - Missing comments are replaced with empty strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "train_data['comments'] = train_data['comments'].fillna('')\n",
    "test_data['comments'] = test_data['comments'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature 2: Grades - Encode categorical values of grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def grade_encoder(dataset):\n",
    "    grade_encoding = pd.get_dummies(dataset['grade'])\n",
    "    grade_encoding_as_array = np.asarray(grade_encoding)\n",
    "    \n",
    "    grade_encoding_as_df = [grade_encoding_as_array[x].tostring() for x in xrange(len(dataset))]\n",
    "    dataset['grade_encoding'] = pd.DataFrame(grade_encoding_as_df)\n",
    "\n",
    "grade_encoder(train_data)\n",
    "grade_encoder(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.base import BaseEstimator, TransformerMixin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split training data - 75% for training, 25% for validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train, test = train_test_split(trainData)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using sklearn's FeatureUnion to parallely encode categorical data in Features\n",
    "#### FeatureUnion useful when\n",
    "#### 1) Dataset has heterogenous data types\n",
    "#### 2) Different columns require different pre-processing Pipelines\n",
    "\n",
    "### FeatureUnion combines several 'transformer' objects "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer class for comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class textExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def transform(self,data):\n",
    "        return np.asarray(data[self.factor])\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transformer class for tags\n",
    "### Each tag is first cleaned using regex and then encoded based on a separator. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "parserForTag = lambda x : re.sub(\"[^\\Sa-zA-Z]\", \"\", x).replace(\"\\\"\",\"\").replace(\"[\",\"\").replace(\"]\",\"\").replace(\"\\'\",\"\").replace('.',\"\").replace('?',\"\").lower().split(\",\")\n",
    "\n",
    "class tagExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "    \n",
    "    def transform(self, data):\n",
    "        return np.asarray(data[self.factor].map(parserForTag).str.join(sep='*').str.get_dummies(sep='*'))\n",
    "\n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class interestExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def transform(self,data):\n",
    "        return pd.get_dummies(data[self.factor])\n",
    "        \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class gradeExtractor(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "        \n",
    "    def transform(self,data):\n",
    "        outputGrades = []\n",
    "        for content in data[self.factor]:\n",
    "            outputGrades.append(np.fromstring(content))\n",
    "        return outputGrades\n",
    "    \n",
    "    def fit(self, *_):\n",
    "        return self"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments are converted to a matrix of TF-IDF features. 30000 features are used in the final model\n",
    "\n",
    "### All the individual transformer objects are concatenated to a single transformer using the FeatureUnion estimator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 6 candidates, totalling 18 fits\n"
     ]
    }
   ],
   "source": [
    "comments_featurizer = Pipeline([\n",
    "        ('comments_extractor', textExtractor('comments')),\n",
    "        ('comments_tdidf', TfidfVectorizer(max_df=0.95, \n",
    "                                           min_df=1,  \n",
    "                                           max_features=30000,\n",
    "                                           ngram_range = (1,3)))\n",
    "    ])\n",
    "\n",
    "tags_featurizer = Pipeline([\n",
    "        ('tags_extractor', tagExtractor('tags'))\n",
    "    ])\n",
    "\n",
    "interest_featurizer = Pipeline([\n",
    "        ('interest_extractor', interestExtractor('interest'))\n",
    "    ])\n",
    "\n",
    "grade_featurizer = Pipeline([\n",
    "        ('grade_extractor', gradeExtractor('gradeContent'))\n",
    "    ])\n",
    "\n",
    "textBook_featurizer = Pipeline([\n",
    "        ('textBook_extractor', interestExtractor('textbookuse'))\n",
    "    ])\n",
    "\n",
    "features = FeatureUnion([        \n",
    "        ('comments_features', comments_featurizer),\n",
    "        ('interest_features', interest_featurizer),        \n",
    "        ('tag_features', tags_featurizer),\n",
    "        ('grade_features', grade_featurizer)\n",
    "    ])\n",
    "\n",
    "pipeline = Pipeline([\n",
    "  ('feature_union', features),\n",
    "  ('regression', Ridge())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tuning the hyperparameters and cross-validation using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "alphas = np.array([3,1,0.1]) \n",
    "max_iter = np.array([800, 1300])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = GridSearchCV(\n",
    "    pipeline, param_grid=dict(regression__alpha=alphas, regression__max_iter=max_iter), n_jobs=-1, verbose=10\n",
    ").fit(train[['comments', 'interest','tags','grade','gradeContent','textbookuse']], train['quality'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Output the best score, this is based on held out data in cross validation\n",
    "print(\"R Squared: {}\".format(cv.best_score_))\n",
    "\n",
    "# Output the Mean Squared Error using our held out training data\n",
    "from sklearn.metrics import mean_squared_error\n",
    "mse = mean_squared_error(test['quality'], cv.predict(test[['comments','interest','tags','grade','gradeContent','textbookuse']]))\n",
    "print(\"MSE: {}\".format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Make training predictions\n",
    "predictions = cv.predict(testData[['comments', 'interest','tags','grade','gradeContent','textbookuse']])\n",
    "\n",
    "# Lets take a quick look at the predictions to make sure they are sensible, seems like it\n",
    "predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Any score less than 2 and above 10 are clipped to 2 and 10 respectively. This small hack reduced the MSE by ~0.06. Done using the clip function in numpy!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Finally lets write out the predictions with their id's\n",
    "\n",
    "with open('predictions.csv', 'w') as f:\n",
    "    f.write(\"id,quality\\n\")\n",
    "    for row_id, prediction in zip(testData['id'], np.clip(predictions, 2, 10)):\n",
    "        f.write('{},{}\\n'.format(row_id, prediction))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
